# ğŸŒ RL-Enhanced GHG Consultant Chatbot

> **Fine-Tuning Language Models through Reinforcement Learning for GHG Compliance**  
> *By The Rewards Musketeers*

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Tested on Windows & macOS](https://img.shields.io/badge/platform-Windows%20%7C%20macOS-lightgrey)]()

An intelligent GHG (Greenhouse Gas) consulting chatbot that uses **Reinforcement Learning** to optimize document retrieval in RAG (Retrieval-Augmented Generation) systems. We demonstrate that RL agents (Q-Learning & PPO) learn superior retrieval policies compared to fixed baseline strategies.

---

## ğŸš€ Overview

Traditional RAG systems use static retrieval strategies. We improve this by training RL agents to **dynamically select optimal document filters** based on question characteristics. Our system learns which documents (legal, financial, technical) to retrieve for each query type, improving answer quality by **6-8%**.

**Key Innovation:** Multi-component reward function evaluating answer quality, retrieval relevance, grounding, and policy diversity â€” enabling interpretable, continuously improving chatbot behavior.

---

## ğŸ§  Architecture

```
User Question â†’ State Encoder â†’ RL Agent (Q-Learning/PPO) â†’ Document Filter
                                           â†“
                                    RAG Process â†” ChromaDB
                                           â†“
                                      LLM (Groq) â†’ Answer
                                           â†“
                                   Reward Calculation â† Judge Evaluation
                                           â†“
                                   Update RL Agent
```

---

## ğŸ¯ Results

*(N=40 test questions, evaluated by GPT-4o-mini judge)*

| Method | Avg Judge Score | Improvement | User Feedback |
|--------|-----------------|-------------|---------------|
| **Baseline** (no RL) | 0.830 | - | 100% ğŸ‘ |
| **Q-Learning** | 0.880 | +6.0% | 90% ğŸ‘ |
| **PPO** | 0.900 | +8.4% | 100% ğŸ‘ |

![Results Comparison](docs/images/complete_comparison_3methods.png)

â†’ **[Full Experiment Logs & Analysis](logs/comparisons/)**

---

## ğŸ§© Components

Our system consists of:

- **ğŸ” RAG Pipeline** â€“ Retrieves relevant GHG documents using ChromaDB vector database
- **ğŸ® Q-Learning Agent** â€“ Tabular RL learning retrieval policies (Î±=0.3, Î³=0.9, Îµ=0.2)
- **ğŸ§  PPO Agent** â€“ Neural network-based policy optimization (clip=0.2, GAE Î»=0.95)
- **ğŸ¯ Multi-Component Reward** â€“ Evaluates quality, relevance, grounding, diversity (50%+20%+15%+15%)
- **âš–ï¸ LLM-as-Judge** â€“ GPT-4o-mini evaluates answers without ground truth access

### Reward Function Summary:
```python
total_reward = 0.5 * judge_score      # Answer quality [0,1]
             + 0.2 * retrieval_score  # Chunk relevance [0,1]
             + 0.15 * action_score    # Policy diversity [0,1]
             + 0.15 * grounding_score # Citation quality [0,1]
```

â†’ **[Complete Technical Documentation](docs/STUDY.md)** (2,350+ lines)

---

## âš™ï¸ Quick Start

### **1. Installation**

```bash
# Clone repository
git clone https://github.com/MaithaAlhammadi98/RL-GHG-Consultant.git
cd RL-GHG-Consultant

# Install dependencies (Python 3.10+ recommended)
pip install -r requirements.txt
```

### **2. Setup Environment**

```bash
# Copy environment template and add your API keys
cp .env.example .env
# Edit .env with your GROQ_API_KEY and OPENAI_API_KEY
```

### **3. Populate Database**

```bash
# Generate ChromaDB vector store from PDF documents
python populate_database.py
```

### **4. Run Interactive Demo**

```bash
# Launch Gradio interface at http://localhost:7860
python three_bot_demo.py
```

**Features:**
- ğŸ¤– Compare all 3 bots side-by-side
- ğŸ‘ğŸ‘ Train Q-Learning agent with live feedback
- ğŸ“Š Watch Q-table update in real-time

### **5. Run Full Experiment**

```bash
# Train & evaluate all methods, generate comparison plots
python complete_experiment.py
```

---

## ğŸ“ Project Structure

```
RL-GHG-Consultant/
â”œâ”€â”€ src/backend/           # Core RL & RAG implementation
â”‚   â”œâ”€â”€ rl_agent.py       # Q-Learning agent
â”‚   â”œâ”€â”€ ppo_agent.py      # PPO agent
â”‚   â”œâ”€â”€ rag_process.py    # RAG pipeline
â”‚   â”œâ”€â”€ reward_enhanced.py # Multi-component reward
â”‚   â””â”€â”€ state.py          # State encoder
â”œâ”€â”€ three_bot_demo.py     # ğŸ® Interactive Gradio demo
â”œâ”€â”€ complete_experiment.py # ğŸ“Š Full experiment runner
â”œâ”€â”€ populate_database.py  # ğŸ—„ï¸ Database setup
â”œâ”€â”€ docs/                 # ğŸ“š Documentation
â”‚   â”œâ”€â”€ STUDY.md         # Complete technical guide
â”‚   â””â”€â”€ images/          # Result visualizations
â”œâ”€â”€ logs/                 # ğŸ“ˆ Experiment results
â”‚   â”œâ”€â”€ baseline/
â”‚   â”œâ”€â”€ qlearning/
â”‚   â”œâ”€â”€ ppo/
â”‚   â””â”€â”€ comparisons/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ REPORT.md            # ğŸ“„ Final project report (TBD)
```

## ğŸ“Š Key Findings

1. âœ… **Consistent RL Improvement** â€“ Both agents outperform baseline (+6% Q-Learning, +8% PPO)
2. ğŸ§  **Interpretable Policies** â€“ Q-table shows learned state-action preferences
3. ğŸ”„ **Live Learning Works** â€“ Interactive demo proves real-time policy updates
4. ğŸ¯ **Reward Design Matters** â€“ Multi-component feedback enables nuanced learning

---

## ğŸ‘¥ Team

**The Rewards Musketeers**

This project was developed as part of an AI/RL course demonstrating practical applications of reinforcement learning to improve LLM-based systems.

---

## ğŸ™ Acknowledgements

- **Groq** for fast LLM inference (Llama-3.1-8b-instant)
- **OpenAI** for GPT-4o-mini judge evaluation
- **ChromaDB** for vector database infrastructure
- **Gradio** for interactive demo interface

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

**Built with:** Python â€¢ PyTorch â€¢ Groq â€¢ ChromaDB â€¢ Gradio  
**RL Algorithms:** Q-Learning â€¢ Proximal Policy Optimization (PPO)  
**Tested on:** Python 3.10.11, Windows 11 & macOS (Apple Silicon)
